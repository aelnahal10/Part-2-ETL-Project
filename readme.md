```markdown
# ğŸª Retail ETL Project â€“ From OLTP to OLAP with SQL Server, Python & Prefect

A complete end-to-end ETL pipeline that transforms a normalized OLTP schema (from an e-commerce retail system) into a clean OLAP star schema, using **SQL Server**, **Python**, **Prefect**, and **SQLAlchemy**.

---

## ğŸš€ Project Overview

- âœ… **OLTP Dataset**: [Bike Store Sample](https://www.kaggle.com/datasets/dillonmyrick/bike-store-sample-database)
- ğŸ¯ **Goal**: Build a data warehouse (`retail_dw`) for analytics, based on star schema and SCDs
- ğŸ› ï¸ **Tech Stack**: SQL Server, Python, Pandas, Prefect, SQLAlchemy
- ğŸ“Š **BI Ready**: Designed for Power BI or Tableau consumption

---

## ğŸ“ Project Structure

```

etl\_project/
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ create\_olap\_schema.sql
â”‚   â”œâ”€â”€ stage\_tables.sql
â”‚   â”œâ”€â”€ populate\_dim\_date.sql
â”‚   â”œâ”€â”€ scd\_type1\_product.sql
â”‚   â”œâ”€â”€ scd\_type2\_customer.sql
â”‚   â”œâ”€â”€ scd\_type1\_store.sql
â”‚   â”œâ”€â”€ scd\_type2\_staff.sql
â”‚   â””â”€â”€ build\_fact\_sales.sql
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ flow\.py
â”‚   â”œâ”€â”€ load\_staging.py
â”œâ”€â”€ config.py
â”œâ”€â”€ .env
â”œâ”€â”€ README.md
â””â”€â”€ data/
â”œâ”€â”€ customers.csv
â”œâ”€â”€ products.csv
â”œâ”€â”€ ...

````

---

## ğŸ§± Features

- âœ… Builds staging, dimension & fact tables
- ğŸ” Handles **SCD Type 1** and **SCD Type 2** logic
- ğŸ§  Supports surrogate keys and time-based tracking
- âš™ï¸ Automates workflow using **Prefect**
- ğŸ§ª Easily testable with `.csv` source files

---

## ğŸ”§ Requirements

Install the following dependencies:

```bash
pip install -r requirements.txt
````

### `requirements.txt`:

```
pandas
sqlalchemy
pymssql
prefect
python-dotenv
```

---

## ğŸ–¥ï¸ Database Setup

Ensure **SQL Server** is running locally 
---

## ğŸ” .env Configuration

Create a `.env` file at the root with your DB credentials:

```ini
SQL_SERVER=localhost
SQL_PORT=1433
SQL_USER=sa
SQL_PASSWORD=your_password
SQL_DATABASE=retail_dw
```

---

## ğŸ§© Step-by-Step Execution

### 1. Create OLAP Schema

```bash
python python/load_staging.py
```

* Runs `create_olap_schema.sql` and `stage_tables.sql`
* Loads CSVs into staging tables (`stg_*`)

### 2. Run Full ETL

```bash
python python/flow.py
```

* Executes all SQL scripts:

  * Dimensions: SCD Type 1 & 2
  * Date generator
  * Fact builder
* Logs steps to console or Prefect Cloud

---

## ğŸ•’ Optional: Schedule Daily Run (Prefect)

Start Prefect agent:

```bash
prefect agent start --pool default-agent-pool
```

Then deploy flow (already included in `flow.py`):

```bash
python python/flow.py
```

Flow is now scheduled daily via `.serve()`.

---

## ğŸ“Š Power BI / BI Tools

* Connect to `retail_dw` via DirectQuery or Import
* Use `fact_sales` as base table
* Join to `dim_*` via surrogate keys

---

## ğŸ§  Learn More

This project is part of an educational YouTube series on:

* Dimensional Modeling
* SCDs
* ETL Design
* Workflow Automation

Follow the playlist and subscribe for more videos.

---

## ğŸ“¬ Questions?

Reach out via LinkedIn or YouTube if you have questions, suggestions, or want to contribute.

---

```

Let me know if you want a `requirements.txt` generated or a version tailored to self-hosted SQL Server only.
```
